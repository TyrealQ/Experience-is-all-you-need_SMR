{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdA2+iGXxDY1+tp5bIDTxE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TyrealQ/Experience-is-all-you-need_SMR/blob/main/Python_code_SMR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune GPT-3.5"
      ],
      "metadata": {
        "id": "z2tsK8dRvf5s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlcibEOb1dP1"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install openai numpy tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import csv\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "wOStJLwRv161"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up OpenAI API Key securely\n",
        "api_key = userdata.get('YOUR API KEY')\n",
        "client = OpenAI.Client(api_key=api_key)"
      ],
      "metadata": {
        "id": "K2ZCEVWbv-50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Format training dataset"
      ],
      "metadata": {
        "id": "ZZFVZWZvxcZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV data in\n",
        "csv_file_path = 'YOUR CSV FILE PATH'\n",
        "cleaned_data = []\n",
        "\n",
        "with open(csv_file_path, 'r', encoding='utf-8-sig') as file:\n",
        "    csv_reader = csv.reader(file)\n",
        "    for row in csv_reader:\n",
        "        for cell in row:\n",
        "            try:\n",
        "                # Replace square brackets and inner double quotes that are problematic\n",
        "                cell = cell.replace('[\"', '').replace('\"]', '').replace('\\\\\"', '\"')\n",
        "\n",
        "                # Load each cell as a JSON object\n",
        "                cell_json = json.loads(cell)\n",
        "\n",
        "                # Now that the content is clean, append to cleaned_data list\n",
        "                cleaned_data.append(cell_json)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON decode error for cell '{cell}': {e}\")\n",
        "\n",
        "jsonl_file_path = 'YOUR OUTPUT FILE PATH'\n",
        "\n",
        "# Write cleaned data to a JSONL file\n",
        "with open(jsonl_file_path, 'w', encoding='utf-8') as jsonl_file:\n",
        "    for item in cleaned_data:\n",
        "        jsonl_file.write(json.dumps(item) + '\\n')"
      ],
      "metadata": {
        "id": "hDwDSdvhwElS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Double-check the training dataset format and calculate the training cost"
      ],
      "metadata": {
        "id": "YasbmxYuxHJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From OpenAI website to format data;  https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset\n",
        "\n",
        "# Next, we specify the data path and open the JSONL file\n",
        "\n",
        "data_path = 'YOUR JSONL FILE PATH'\n",
        "\n",
        "# Load dataset\n",
        "with open(data_path) as f:\n",
        "    dataset = [json.loads(line) for line in f]\n",
        "\n",
        "# We can inspect the data quickly by checking the number of examples and the first item\n",
        "\n",
        "# Initial dataset stats\n",
        "print(\"Num examples:\", len(dataset))\n",
        "print(\"First example:\")\n",
        "for message in dataset[0][\"messages\"]:\n",
        "    print(message)\n",
        "\n",
        "# Now that we have a sense of the data, we need to go through all the different examples and check to make sure the formatting is correct and matches the structure\n",
        "\n",
        "# Format error checks\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in dataset:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        if not content or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")\n",
        "\n",
        "# Beyond the structure of the message, we also need to ensure that the length does not exceed the 4096 token limit.\n",
        "\n",
        "# Token counting functions\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "# not exact!\n",
        "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
        "\n",
        "# Last, we can look at the results of the different formatting operations before proceeding with creating a fine-tuning job:\n",
        "\n",
        "# Warnings and tokens counts\n",
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in dataset:\n",
        "    messages = ex[\"messages\"]\n",
        "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "        n_missing_system += 1\n",
        "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "        n_missing_user += 1\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(num_tokens_from_messages(messages))\n",
        "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "print_distribution(n_messages, \"num_messages_per_example\")\n",
        "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "n_too_long = sum(l > 4096 for l in convo_lens)\n",
        "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")\n",
        "\n",
        "# Pricing and default n_epochs estimate\n",
        "MAX_TOKENS_PER_EXAMPLE = 4096\n",
        "\n",
        "MIN_TARGET_EXAMPLES = 100\n",
        "MAX_TARGET_EXAMPLES = 25000\n",
        "TARGET_EPOCHS = 4\n",
        "MIN_EPOCHS = 1\n",
        "MAX_EPOCHS = 25\n",
        "\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(dataset)\n",
        "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
        "    n_epochs = min(MAX_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
        "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
        "    n_epochs = max(MIN_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
        "\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
        "\n",
        "# Calculate the estimated cost for fine-tuning\n",
        "cost_per_100k_tokens = 0.80  # Cost for every 100,000 tokens\n",
        "estimated_cost = ((n_epochs * n_billing_tokens_in_dataset) / 100000) * cost_per_100k_tokens\n",
        "print(f\"Estimated cost for fine-tuning: approximately ${estimated_cost:.2f}\") #I added this for actual cost based on current pricing"
      ],
      "metadata": {
        "id": "yJvNZc3nwWdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the finalized training dataset"
      ],
      "metadata": {
        "id": "sRUhFFnPyFi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to save the dataset as a JSONL file\n",
        "def save_to_jsonl(conversations, file_path):\n",
        "    with open(file_path, 'w') as file:\n",
        "        for conversation in conversations:\n",
        "            json_line = json.dumps(conversation)\n",
        "            file.write(json_line + '\\n')\n",
        "\n",
        "# Specify the path where you want to save the JSONL file in your Google Drive\n",
        "jsonl_file_path = 'YOUR FILE PATH'\n",
        "# Save the dataset to the specified file path\n",
        "save_to_jsonl(dataset, jsonl_file_path)"
      ],
      "metadata": {
        "id": "fKxUCknqxFp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the dataset for training"
      ],
      "metadata": {
        "id": "cnXl67PqyJ5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload data for training\n",
        "training_file_name = 'YOUR FILE PATH'\n",
        "\n",
        "training_response = client.files.create(\n",
        "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "training_file_id = training_response.id\n",
        "\n",
        "# Gives training file id\n",
        "print(\"Training file id:\", training_file_id)"
      ],
      "metadata": {
        "id": "O7pYNJQuyPpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Fine-Tuning Job\n",
        "suffix_name = \"CREATE A NAME FOR YOUR MODEL\"\n",
        "\n",
        "# You can stick to the default hyperparameters or adjust some of them based on your data. For example, I set epochs to 4.\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file_id,\n",
        "    model=\"gpt-3.5-turbo-1106\",\n",
        "    suffix=suffix_name,\n",
        "    hyperparameters={\n",
        "    \"n_epochs\":4\n",
        "  }\n",
        ")\n",
        "\n",
        "job_id = response.id\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "paCNg7Qaycyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List events as fine-tuning progresses\n",
        "response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=50)\n",
        "\n",
        "events = response.data\n",
        "events.reverse()\n",
        "\n",
        "for event in events:\n",
        "    print(event.message)"
      ],
      "metadata": {
        "id": "HtwIGJRCyeWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve fine-tune model id\n",
        "response = client.fine_tuning.jobs.retrieve(job_id)\n",
        "fine_tuning_job_id = response.fine_tuned_model\n",
        "\n",
        "print(response)\n",
        "print(\"\\nFine-tuned model id:\", fine_tuning_job_id)"
      ],
      "metadata": {
        "id": "6lZoT2ulyhCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running the fine-tuned GPT-3.5 models for AE & CC"
      ],
      "metadata": {
        "id": "gp-oCB1IzeDF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the AE model for CX aspect extraction:\n",
        "\n",
        "ft:gpt-3.5-turbo-1106:qian:cxae:8kZXONLd\n"
      ],
      "metadata": {
        "id": "CVxVSrWqzsHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "txsnXed0zlmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "\n",
        "# Set up OpenAI API Key securely\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('YOUR API KEY')\n",
        "client = openai.client(api_key=api_key)\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('YOUR FILE PATH')\n",
        "\n",
        "# Create a new column in the DataFrame to store the results\n",
        "df['Aspect'] = ''\n",
        "\n",
        "# Define the system prompt\n",
        "system_prompt = (\"\"\"\n",
        "    You are an expert in college football, specializing in analyzing Tripadvisor reviews of college football stadiums, focusing on game day experiences.\n",
        "    Each review consists of sentences that need to be treated individually. Within these sentences, identify various aspects of the game day experience, noting that a single aspect can have multiple descriptions.\n",
        "    For aspect extraction in each sentence of a review, the process must be followed carefully. Ensure each step is taken one at a time for optimal clarity and results:\n",
        "    1. Analyze each sentence as a separate unit.\n",
        "    2. Identify the different aspects of the game day experience mentioned.\n",
        "    3. For aspects with multiple descriptions within the same sentence, list each description as a separate entry, including the aspect in the detail for clarity.\n",
        "    4. Extract each aspect and its corresponding detailed description.\n",
        "    5. Format this information in a JSON structure using '''Aspect_i''' and '''Details_i''' as keys, incrementing '''i''' for each new aspect or unique description.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    if pd.notna(row['Text']):\n",
        "        conversation = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": row['Text']}\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"ft:gpt-3.5-turbo-1106:qian:cxae:8kZXONLd\",\n",
        "                messages=conversation,\n",
        "                temperature=0,\n",
        "                max_tokens=2048\n",
        "            )\n",
        "                #response_format={ \"type\": \"json_object\" }\n",
        "\n",
        "            # Assuming the response is an object with attributes, we use dot notation\n",
        "            # If this raises an error, then your environment may be different and require dictionary access\n",
        "            content = response.choices[0].message.content\n",
        "\n",
        "            # Debug: Print the response\n",
        "            print(f\"Index {index} - Response: {content}\")\n",
        "\n",
        "            # Assign the response to the DataFrame\n",
        "            df.at[index, 'Aspect'] = content\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing index {index}: {e}\")\n",
        "    else:\n",
        "        print(f\"Skipping index {index}: 'Text' column is NaN\")\n",
        "\n",
        "# Debug: Print the DataFrame before saving\n",
        "print(df.head())\n",
        "\n",
        "# Save the DataFrame\n",
        "df.to_csv('YOUR FILE PATH', index=False)"
      ],
      "metadata": {
        "id": "Yept7qTzzoek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the CC model for CX classification:\n",
        "\n",
        "ft:gpt-3.5-turbo-1106:qian:cxcc:8mNAEN0D"
      ],
      "metadata": {
        "id": "QDKJyTyG0Hj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "KdqYOuJa0Sl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai as OpenAI\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set up OpenAI API Key securely\n",
        "api_key = userdata.get('YOUR API KEY')\n",
        "client = OpenAI.Client(api_key=api_key)\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('YOUR FILE PATH')\n",
        "\n",
        "# Create a new column in the DataFrame to store the results\n",
        "df['Label1'] = ''\n",
        "\n",
        "# Define the system prompt\n",
        "system_prompt = (\"\"\"\n",
        "    You are an expert in college football, specializing in categorizing aspects of the college football game day experience, identified from Tripadvisor online reviews of college football stadiums.\n",
        "    Each identified aspect ('''Aspect_i''') has a corresponding description ('''Details_i''') that you will use to determine its appropriate category.\n",
        "    The categories are 'Core', 'Functional', 'Emotional', 'Monetary', 'Social', 'Safety', and 'Others'.\n",
        "    Your task is to analyze each aspect's description and classify it accordingly.\n",
        "    Ensure each step is taken one at a time for optimal clarity and results:\n",
        "    1. Examine the description ('''Details_i''') of each aspect ('''Aspect_i''').\n",
        "    2. Classify '''Aspect_i''' into one of the following categories based on '''Details_i''':\n",
        "    'Core': Sports-related attributes (e.g., team dynamics, game quality).\n",
        "    'Functional': utilitarian services (e.g., facilities, concessions, parking).\n",
        "    'Emotional': Feelings or emotional states (e.g., excitement, thrill).\n",
        "    'Monetary': Pricing aspects (e.g., affordability, value for money).\n",
        "    'Social': Interpersonal and community aspects (e.g., fan interactions, traditions).\n",
        "    'Safety': Security and safety experiences (e.g., measures, feelings of safety).\n",
        "    'Others': Aspects unrelated to the college football game day experience or that do not fit into the other categories, such as general comments about the city or weather conditions.\n",
        "    3. Format this classification into a JSON structure using '''Aspect_i''' and '''Label_i''' as keys, incrementally assigning '''i''' for each aspect.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    if pd.notna(row['Aspect1']):\n",
        "        conversation = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": row['Aspect1']}\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"ft:gpt-3.5-turbo-1106:qian:cxcc:8mNAEN0D\",\n",
        "                messages=conversation,\n",
        "                temperature=0,\n",
        "                max_tokens=2048\n",
        "            )\n",
        "            #response_format={ \"type\": \"json_object\" }\n",
        "\n",
        "            # Assuming the response is an object with attributes, we use dot notation\n",
        "            # If this raises an error, then your environment may be different and require dictionary access\n",
        "            content = response.choices[0].message.content\n",
        "\n",
        "            # Debug: Print the response\n",
        "            print(f\"Index {index} - Response: {content}\")\n",
        "\n",
        "            # Assign the response to the DataFrame\n",
        "            df.at[index, 'Label1'] = content\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing index {index}: {e}\")\n",
        "    else:\n",
        "        print(f\"Skipping index {index}: 'Text' column is NaN\")\n",
        "\n",
        "# Debug: Print the DataFrame before saving\n",
        "print(df.head())\n",
        "\n",
        "# Save the DataFrame\n",
        "df.to_csv('YOUR FILE PATH', index=False)"
      ],
      "metadata": {
        "id": "aH8CqrlU0UF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RoBERTa sentiment assessment and model evaluation"
      ],
      "metadata": {
        "id": "t1IltEBh1KkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "HPSXPVV-1QVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from scipy.special import softmax"
      ],
      "metadata": {
        "id": "xXj4tRBB5O01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify model\n",
        "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
      ],
      "metadata": {
        "id": "k6ueSjUk3JIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment assessment"
      ],
      "metadata": {
        "id": "eLN0_kkU49Qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your original DataFrame\n",
        "df = pd.read_csv('YOUR FILE PATH')\n",
        "\n",
        "# Full classification\n",
        "def polarity_scores_roberta(example):\n",
        "    encoded_text = tokenizer(example, return_tensors='pt')\n",
        "    output = model(**encoded_text)\n",
        "    scores = output[0][0].detach().numpy()\n",
        "    scores = softmax(scores)\n",
        "    scores_dict = {\n",
        "        'neg': scores[0],\n",
        "        'neu': scores[1],\n",
        "        'pos': scores[2]\n",
        "    }\n",
        "    return scores_dict\n",
        "\n",
        "res = []\n",
        "\n",
        "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    try:\n",
        "        myid = row['review_id']\n",
        "        result_dict = {'review_id': myid}  # Initialize result_dict with ID\n",
        "\n",
        "        for j in range(1, 29):  # This will loop through numbers 1 to 28\n",
        "            column_name = f'text_{j}'\n",
        "\n",
        "            # Check for missing values before converting to string\n",
        "            if pd.isna(row[column_name]):\n",
        "                roberta_result = {'neg': 0, 'neu': 0, 'pos': 0}\n",
        "            else:\n",
        "                text = str(row[column_name])  # Convert to string only if not missing\n",
        "                roberta_result = polarity_scores_roberta(text)\n",
        "\n",
        "            # Update result_dict with polarity scores for this column\n",
        "            result_dict.update({\n",
        "                f'{column_name}_neg': roberta_result['neg'],\n",
        "                f'{column_name}_neu': roberta_result['neu'],\n",
        "                f'{column_name}_pos': roberta_result['pos']\n",
        "            })\n",
        "\n",
        "        # Append the result_dict to res list after processing all columns for this row\n",
        "        res.append(result_dict)\n",
        "    except Exception as e:  # Catch all exceptions for debugging\n",
        "        print(f'Broke for id{myid}, column {column_name}, error: {e}')\n",
        "\n",
        "# Convert the list of dictionaries to a DataFrame\n",
        "results_df = pd.DataFrame(res)\n",
        "\n",
        "# Ensure the path for saving the CSV file is correct\n",
        "# ...\n",
        "results_df.to_csv('YOUR FILE PATH', index=False)"
      ],
      "metadata": {
        "id": "g6Xv25NI3P6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model evaluation"
      ],
      "metadata": {
        "id": "Oh2guXYX5BGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "qXg5KCSp411D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "nYpabtDk5MQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load the data\n",
        "data_path = 'YOUR EVAL DATA PATH'\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Assuming you have a column named 'Text' with the data and 'Label' with the labels (positive-2, negative-0, and neutral-1)\n",
        "texts = df['Details'].tolist()\n",
        "labels = df['Label'].tolist()\n",
        "\n",
        "# 2. Tokenize the data\n",
        "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "tokenizer = RobertaTokenizer.from_pretrained(MODEL)\n",
        "inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "\n",
        "# 3. Load the pretrained RoBERTa model\n",
        "model = RobertaForSequenceClassification.from_pretrained(MODEL)\n",
        "model.eval()\n",
        "\n",
        "# 4. Predict the sentiments\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=1).tolist()\n",
        "\n",
        "# 5. Evaluate metrics\n",
        "conf_matrix = confusion_matrix(labels, predictions)\n",
        "accuracy = accuracy_score(labels, predictions)\n",
        "precision = precision_score(labels, predictions, average='weighted')\n",
        "recall = recall_score(labels, predictions, average='weighted')\n",
        "f1 = f1_score(labels, predictions, average='weighted')\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "ANBxj1UM5TO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary logistic regression"
      ],
      "metadata": {
        "id": "wt0kEG8MRfOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "kqXnDskkRieI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'YOUR FILE PATH'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Independent variables\n",
        "X = data[['Core_pos_scores', 'Core_neg_scores', 'Functional_pos_scores', 'Functional_neg_scores',\n",
        "          'Emotional_pos_scores', 'Emotional_neg_scores', 'Social_pos_scores', 'Social_neg_scores',\n",
        "          'Monetary_pos_scores', 'Monetary_neg_scores', 'Safety_pos_scores', 'Safety_neg_scores']]\n",
        "y = data['Rating_D']\n",
        "\n",
        "# Display means for the independent variables, rounded to two decimal places\n",
        "means = X.mean().round(2)\n",
        "std_devs = X.std().round(2)\n",
        "\n",
        "# Combine means and standard deviations into one DataFrame\n",
        "stats = pd.concat([means.to_frame('Mean'), std_devs.to_frame('Standard Deviation')], axis=1)\n",
        "print(\"Statistics of the independent variables:\")\n",
        "print(stats)\n",
        "\n",
        "# Add a constant to the independent variable set\n",
        "X_with_const = sm.add_constant(X)\n",
        "\n",
        "# Fit the logistic regression model\n",
        "logit_model = sm.Logit(y, X_with_const)\n",
        "result = logit_model.fit()\n",
        "\n",
        "# Print the summary of the logistic regression rounded to two decimal places\n",
        "print(result.summary2().tables[1].round(2))\n",
        "\n",
        "# Function to calculate the exponential of the coefficients (Exp(B))\n",
        "def calculate_exp_b(coefficients):\n",
        "    return np.exp(coefficients)\n",
        "\n",
        "# Calculate Exp(B) and the effects of a 0.1 unit increase\n",
        "exp_b_values = calculate_exp_b(result.params)\n",
        "effects_0_1 = np.exp(result.params * 0.1)\n",
        "\n",
        "# Create DataFrames to display Exp(B) values and effects of a 0.1 unit increase in a structured format\n",
        "exp_b_df = pd.DataFrame({\n",
        "    \"Exp(B)\": exp_b_values,\n",
        "    \"Exp(B) of 0.1 Unit Increase\": effects_0_1\n",
        "}).round(2)\n",
        "\n",
        "print(\"\\nExp(B) values and Exp(B) of a 0.1 Unit Increase on Odds:\")\n",
        "print(exp_b_df)"
      ],
      "metadata": {
        "id": "zeQ8Cb0zSUM1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}